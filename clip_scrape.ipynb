{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting NBA possession data updater for 2025 season...\n",
      "\n",
      "Processing ATL...\n",
      "2025\n",
      "Updating ATL data from 2025-02-11 to 2025-02-24\n",
      "Fetched 231 possessions for ATL from 2025-02-11 to 2025-02-17\n",
      "Fetched 196 possessions for ATL from 2025-02-18 to 2025-02-24\n",
      "Added 918 new possessions to nba_possessions_data/2025/2025_ATL_possessions.csv\n",
      "\n",
      "Processing BKN...\n",
      "2025\n",
      "Updating BKN data from 2025-02-11 to 2025-02-24\n",
      "Fetched 186 possessions for BKN from 2025-02-11 to 2025-02-17\n",
      "Fetched 386 possessions for BKN from 2025-02-18 to 2025-02-24\n",
      "Added 1172 new possessions to nba_possessions_data/2025/2025_BKN_possessions.csv\n",
      "\n",
      "Processing BOS...\n",
      "2025\n",
      "Updating BOS data from 2025-02-11 to 2025-02-24\n",
      "Fetched 197 possessions for BOS from 2025-02-11 to 2025-02-17\n",
      "Fetched 190 possessions for BOS from 2025-02-18 to 2025-02-24\n",
      "Added 755 new possessions to nba_possessions_data/2025/2025_BOS_possessions.csv\n",
      "\n",
      "Processing CHA...\n",
      "2025\n",
      "Updating CHA data from 2025-02-11 to 2025-02-24\n",
      "Fetched 186 possessions for CHA from 2025-02-11 to 2025-02-17\n",
      "Fetched 614 possessions for CHA from 2025-02-18 to 2025-02-24\n",
      "Added 1594 new possessions to nba_possessions_data/2025/2025_CHA_possessions.csv\n",
      "\n",
      "Processing CHI...\n",
      "2025\n",
      "Updating CHI data from 2025-02-12 to 2025-02-24\n",
      "Fetched 209 possessions for CHI from 2025-02-12 to 2025-02-18\n",
      "Fetched 422 possessions for CHI from 2025-02-19 to 2025-02-24\n",
      "Added 1228 new possessions to nba_possessions_data/2025/2025_CHI_possessions.csv\n",
      "\n",
      "Processing CLE...\n",
      "2025\n",
      "Updating CLE data from 2025-02-11 to 2025-02-24\n",
      "Fetched 206 possessions for CLE from 2025-02-11 to 2025-02-17\n",
      "Fetched 406 possessions for CLE from 2025-02-18 to 2025-02-24\n",
      "Added 1206 new possessions to nba_possessions_data/2025/2025_CLE_possessions.csv\n",
      "\n",
      "Processing DAL...\n",
      "2025\n",
      "Updating DAL data from 2025-02-11 to 2025-02-24\n",
      "Fetched 386 possessions for DAL from 2025-02-11 to 2025-02-17\n",
      "Fetched 205 possessions for DAL from 2025-02-18 to 2025-02-24\n",
      "Added 1189 new possessions to nba_possessions_data/2025/2025_DAL_possessions.csv\n",
      "\n",
      "Processing DEN...\n",
      "2025\n",
      "Updating DEN data from 2025-02-11 to 2025-02-24\n",
      "Fetched 208 possessions for DEN from 2025-02-11 to 2025-02-17\n",
      "Fetched 395 possessions for DEN from 2025-02-18 to 2025-02-24\n",
      "Added 1209 new possessions to nba_possessions_data/2025/2025_DEN_possessions.csv\n",
      "\n",
      "Processing DET...\n",
      "2025\n",
      "Updating DET data from 2025-02-12 to 2025-02-24\n",
      "Fetched 209 possessions for DET from 2025-02-12 to 2025-02-18\n",
      "Fetched 200 possessions for DET from 2025-02-19 to 2025-02-24\n",
      "Added 820 new possessions to nba_possessions_data/2025/2025_DET_possessions.csv\n",
      "\n",
      "Processing GSW...\n",
      "2025\n",
      "Updating GSW data from 2025-02-11 to 2025-02-24\n",
      "Fetched 393 possessions for GSW from 2025-02-11 to 2025-02-17\n",
      "Fetched 192 possessions for GSW from 2025-02-18 to 2025-02-24\n",
      "Added 1162 new possessions to nba_possessions_data/2025/2025_GSW_possessions.csv\n",
      "\n",
      "Processing HOU...\n",
      "2025\n",
      "Updating HOU data from 2025-02-10 to 2025-02-24\n",
      "Fetched 400 possessions for HOU from 2025-02-10 to 2025-02-16\n",
      "Fetched 406 possessions for HOU from 2025-02-17 to 2025-02-23\n",
      "Added 1645 new possessions to nba_possessions_data/2025/2025_HOU_possessions.csv\n",
      "\n",
      "Processing IND...\n",
      "2025\n",
      "Updating IND data from 2025-02-12 to 2025-02-24\n",
      "Fetched 217 possessions for IND from 2025-02-12 to 2025-02-18\n",
      "Fetched 202 possessions for IND from 2025-02-19 to 2025-02-24\n",
      "Added 822 new possessions to nba_possessions_data/2025/2025_IND_possessions.csv\n",
      "\n",
      "Processing LAC...\n",
      "2025\n",
      "Updating LAC data from 2025-02-09 to 2025-02-24\n",
      "Fetched 420 possessions for LAC from 2025-02-09 to 2025-02-15\n",
      "Fetched 194 possessions for LAC from 2025-02-16 to 2025-02-22\n",
      "Fetched 0 possessions for LAC from 2025-02-23 to 2025-02-24\n",
      "Added 1205 new possessions to nba_possessions_data/2025/2025_LAC_possessions.csv\n",
      "\n",
      "Processing LAL...\n",
      "2025\n",
      "Updating LAL data from 2025-02-09 to 2025-02-24\n",
      "Fetched 412 possessions for LAL from 2025-02-09 to 2025-02-15\n",
      "Fetched 600 possessions for LAL from 2025-02-16 to 2025-02-22\n",
      "Fetched 0 possessions for LAL from 2025-02-23 to 2025-02-24\n",
      "Added 1986 new possessions to nba_possessions_data/2025/2025_LAL_possessions.csv\n",
      "\n",
      "Processing MEM...\n",
      "2025\n",
      "Updating MEM data from 2025-02-12 to 2025-02-24\n",
      "Fetched 207 possessions for MEM from 2025-02-12 to 2025-02-18\n",
      "Fetched 404 possessions for MEM from 2025-02-19 to 2025-02-24\n",
      "Added 1242 new possessions to nba_possessions_data/2025/2025_MEM_possessions.csv\n",
      "\n",
      "Processing MIA...\n",
      "2025\n",
      "Updating MIA data from 2025-02-11 to 2025-02-24\n",
      "Fetched 384 possessions for MIA from 2025-02-11 to 2025-02-17\n",
      "Fetched 202 possessions for MIA from 2025-02-18 to 2025-02-24\n",
      "Added 1165 new possessions to nba_possessions_data/2025/2025_MIA_possessions.csv\n",
      "\n",
      "Processing MIL...\n",
      "2025\n",
      "Updating MIL data from 2025-02-11 to 2025-02-24\n",
      "Fetched 208 possessions for MIL from 2025-02-11 to 2025-02-17\n",
      "Fetched 393 possessions for MIL from 2025-02-18 to 2025-02-24\n",
      "Added 1188 new possessions to nba_possessions_data/2025/2025_MIL_possessions.csv\n",
      "\n",
      "Processing MIN...\n",
      "2025\n",
      "Updating MIN data from 2025-02-11 to 2025-02-24\n",
      "Fetched 402 possessions for MIN from 2025-02-11 to 2025-02-17\n",
      "Fetched 206 possessions for MIN from 2025-02-18 to 2025-02-24\n",
      "Added 1212 new possessions to nba_possessions_data/2025/2025_MIN_possessions.csv\n",
      "\n",
      "Processing NOP...\n",
      "2025\n",
      "Updating NOP data from 2025-02-11 to 2025-02-24\n",
      "Fetched 415 possessions for NOP from 2025-02-11 to 2025-02-17\n",
      "Fetched 205 possessions for NOP from 2025-02-18 to 2025-02-24\n",
      "Added 1248 new possessions to nba_possessions_data/2025/2025_NOP_possessions.csv\n",
      "\n",
      "Processing NYK...\n",
      "2025\n",
      "Updating NYK data from 2025-02-12 to 2025-02-24\n",
      "Fetched 231 possessions for NYK from 2025-02-12 to 2025-02-18\n",
      "Fetched 422 possessions for NYK from 2025-02-19 to 2025-02-24\n",
      "Added 1249 new possessions to nba_possessions_data/2025/2025_NYK_possessions.csv\n",
      "\n",
      "Processing OKC...\n",
      "2025\n",
      "Updating OKC data from 2025-02-11 to 2025-02-24\n",
      "Fetched 385 possessions for OKC from 2025-02-11 to 2025-02-17\n",
      "Fetched 200 possessions for OKC from 2025-02-18 to 2025-02-24\n",
      "Added 1182 new possessions to nba_possessions_data/2025/2025_OKC_possessions.csv\n",
      "\n",
      "Processing ORL...\n",
      "2025\n",
      "Updating ORL data from 2025-02-11 to 2025-02-24\n",
      "Fetched 186 possessions for ORL from 2025-02-11 to 2025-02-17\n",
      "Fetched 398 possessions for ORL from 2025-02-18 to 2025-02-24\n",
      "Added 1256 new possessions to nba_possessions_data/2025/2025_ORL_possessions.csv\n",
      "\n",
      "Processing PHI...\n",
      "2025\n",
      "Updating PHI data from 2025-02-12 to 2025-02-24\n",
      "Fetched 186 possessions for PHI from 2025-02-12 to 2025-02-18\n",
      "Fetched 374 possessions for PHI from 2025-02-19 to 2025-02-24\n",
      "Added 1103 new possessions to nba_possessions_data/2025/2025_PHI_possessions.csv\n",
      "\n",
      "Processing PHX...\n",
      "2025\n",
      "Updating PHX data from 2025-02-12 to 2025-02-24\n",
      "Fetched 200 possessions for PHX from 2025-02-12 to 2025-02-18\n",
      "Fetched 407 possessions for PHX from 2025-02-19 to 2025-02-24\n",
      "Added 1170 new possessions to nba_possessions_data/2025/2025_PHX_possessions.csv\n",
      "\n",
      "Processing POR...\n",
      "2025\n",
      "Updating POR data from 2025-02-11 to 2025-02-24\n",
      "Fetched 208 possessions for POR from 2025-02-11 to 2025-02-17\n",
      "Fetched 415 possessions for POR from 2025-02-18 to 2025-02-24\n",
      "Added 1241 new possessions to nba_possessions_data/2025/2025_POR_possessions.csv\n",
      "\n",
      "Processing SAC...\n",
      "2025\n",
      "Updating SAC data from 2025-02-11 to 2025-02-24\n",
      "Fetched 415 possessions for SAC from 2025-02-11 to 2025-02-17\n",
      "Fetched 192 possessions for SAC from 2025-02-18 to 2025-02-24\n",
      "Added 1191 new possessions to nba_possessions_data/2025/2025_SAC_possessions.csv\n",
      "\n",
      "Processing SAS...\n",
      "2025\n",
      "Updating SAS data from 2025-02-11 to 2025-02-24\n",
      "Fetched 197 possessions for SAS from 2025-02-11 to 2025-02-17\n",
      "Fetched 403 possessions for SAS from 2025-02-18 to 2025-02-24\n",
      "Added 1165 new possessions to nba_possessions_data/2025/2025_SAS_possessions.csv\n",
      "\n",
      "Processing TOR...\n",
      "2025\n",
      "Updating TOR data from 2025-02-12 to 2025-02-24\n",
      "Fetched 206 possessions for TOR from 2025-02-12 to 2025-02-18\n",
      "Fetched 202 possessions for TOR from 2025-02-19 to 2025-02-24\n",
      "Added 797 new possessions to nba_possessions_data/2025/2025_TOR_possessions.csv\n",
      "\n",
      "Processing UTA...\n",
      "2025\n",
      "Updating UTA data from 2025-02-09 to 2025-02-24\n",
      "Fetched 625 possessions for UTA from 2025-02-09 to 2025-02-15\n",
      "Fetched 400 possessions for UTA from 2025-02-16 to 2025-02-22\n",
      "Fetched 0 possessions for UTA from 2025-02-23 to 2025-02-24\n",
      "Added 2046 new possessions to nba_possessions_data/2025/2025_UTA_possessions.csv\n",
      "\n",
      "Processing WAS...\n",
      "2025\n",
      "Updating WAS data from 2025-02-11 to 2025-02-24\n",
      "Fetched 217 possessions for WAS from 2025-02-11 to 2025-02-17\n",
      "Fetched 199 possessions for WAS from 2025-02-18 to 2025-02-24\n",
      "Added 820 new possessions to nba_possessions_data/2025/2025_WAS_possessions.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "from datetime import timedelta\n",
    "import sys\n",
    "games_url ='https://raw.githubusercontent.com/gabriel1200/shot_data/refs/heads/master/game_dates.csv'\n",
    "games = pd.read_csv(games_url)\n",
    "def get_date_ranges(start_date, end_date):\n",
    "    \"\"\"Generate 7-day date ranges between start and end dates.\"\"\"\n",
    "    start = datetime.datetime.strptime(start_date, '%Y-%m-%d')\n",
    "    end = datetime.datetime.strptime(end_date, '%Y-%m-%d')\n",
    "    \n",
    "    date_ranges = []\n",
    "    current = start\n",
    "    \n",
    "    while current < end:\n",
    "        range_end = min(current + timedelta(days=6), end)\n",
    "        date_ranges.append((\n",
    "            current.strftime('%Y-%m-%d'),\n",
    "            range_end.strftime('%Y-%m-%d')\n",
    "        ))\n",
    "        current = range_end + timedelta(days=1)\n",
    "    \n",
    "    return date_ranges\n",
    "def determine_season(date_str):\n",
    "    \"\"\"Determine the season based on a date string.\"\"\"\n",
    "    year = int(date_str[:4])\n",
    "    month = int(date_str[5:7])\n",
    "    \n",
    "    if month >= 9:  # New season starts around October\n",
    "        return f\"{year}-{str(year+1)[-2:]}\"\n",
    "    else:\n",
    "        return f\"{year-1}-{str(year)[-2:]}\"\n",
    "def fetch_possessions(team, start_date, end_date):\n",
    "    \"\"\"Fetch both offensive and defensive possessions for a team in the given date range.\"\"\"\n",
    "    team_dict = get_team_dict()\n",
    "    season = determine_season(start_date)\n",
    "    url = \"https://api.pbpstats.com/get-possessions/nba\"\n",
    "    \n",
    "    all_possessions = []\n",
    "    \n",
    "    # Fetch offensive possessions\n",
    "    params = {\n",
    "        \"league\": 'nba',\n",
    "        \"TeamId\": team_dict[team],\n",
    "        \"Season\": season,\n",
    "        \"SeasonType\": \"All\",\n",
    "        \"OffDef\": \"Offense\",\n",
    "        \"StartType\": \"All\",\n",
    "        \"FromDate\": start_date,\n",
    "        \"ToDate\": end_date,\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, params=params)\n",
    "        response.raise_for_status()  # Raise exception for HTTP errors\n",
    "        response_json = response.json()\n",
    "        offensive_possessions = response_json.get(\"possessions\", [])\n",
    "        \n",
    "        # Add team info to each possession\n",
    "        for possession in offensive_possessions:\n",
    "            possession['Team'] = team\n",
    "            possession['IsOffense'] = True\n",
    "        \n",
    "        all_possessions.extend(offensive_possessions)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching offensive possessions for {team}: {e}\")\n",
    "    \n",
    "    # Fetch defensive possessions\n",
    "    params['OffDef'] = \"Defense\"\n",
    "    time.sleep(2)\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, params=params)\n",
    "        response.raise_for_status()\n",
    "        response_json = response.json()\n",
    "        defensive_possessions = response_json.get(\"possessions\", [])\n",
    "        \n",
    "        # Add team info to each possession\n",
    "        for possession in defensive_possessions:\n",
    "            possession['Team'] = team\n",
    "            possession['IsOffense'] = False\n",
    "        \n",
    "        all_possessions.extend(defensive_possessions)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching defensive possessions for {team}: {e}\")\n",
    "    \n",
    "    print(f\"Fetched {len(all_possessions)} possessions for {team} from {start_date} to {end_date}\")\n",
    "    return all_possessions\n",
    "def get_team_dict():\n",
    "    \"\"\"Returns a dictionary mapping team abbreviations to team IDs.\"\"\"\n",
    "    return {\n",
    "        'ATL': '1610612737', 'BKN': '1610612751', 'BOS': '1610612738', 'CHA': '1610612766',\n",
    "        'CHI': '1610612741', 'CLE': '1610612739', 'DAL': '1610612742', 'DEN': '1610612743',\n",
    "        'DET': '1610612765', 'GSW': '1610612744', 'HOU': '1610612745', 'IND': '1610612754',\n",
    "        'LAC': '1610612746', 'LAL': '1610612747', 'MEM': '1610612763', 'MIA': '1610612748',\n",
    "        'MIL': '1610612749', 'MIN': '1610612750', 'NOP': '1610612740', 'NYK': '1610612752',\n",
    "        'OKC': '1610612760', 'ORL': '1610612753', 'PHI': '1610612755', 'PHX': '1610612756',\n",
    "        'POR': '1610612757', 'SAC': '1610612758', 'SAS': '1610612759', 'TOR': '1610612761',\n",
    "        'UTA': '1610612762', 'WAS': '1610612764'\n",
    "    }\n",
    "\n",
    "def get_latest_date(file_path):\n",
    "    \"\"\"Get the latest date from CSV where at least one non-NaN URL exists.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Check required columns exist\n",
    "        required_columns = {'GAMEDATE', 'URL'}\n",
    "        if not required_columns.issubset(df.columns):\n",
    "            return None\n",
    "        \n",
    "        # Filter rows with valid URLs\n",
    "        valid_urls = df[df['URL'].notna()]\n",
    "        \n",
    "        if valid_urls.empty:\n",
    "            return None\n",
    "            \n",
    "        return valid_urls['GAMEDATE'].max()\n",
    "        \n",
    "    except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "        return None\n",
    "\n",
    "\n",
    "def convert_new_to_old_format(possession_data, team_id):\n",
    "    \"\"\"Convert new possession data format to match the old CSV structure.\"\"\"\n",
    "    converted_data = []\n",
    "    \n",
    "    for possession in possession_data:\n",
    "        # Extract game teams from the GameId\n",
    "        game_id = possession.get('GameId', '')\n",
    "        game_id = game_id[2:]\n",
    "   \n",
    "      \n",
    "        # Convert events to string\n",
    "        events = ','.join(possession.get('Events', [])) if isinstance(possession.get('Events'), list) else str(possession.get('Events', ''))\n",
    "        \n",
    "        # Get video data\n",
    "        video_data = possession.get('VideoUrls', [])\n",
    "        \n",
    "        if isinstance(video_data, list) and video_data:\n",
    "            # Create a row for each video description/url pair\n",
    "            for video_item in video_data:\n",
    "                row = {\n",
    "                    'ENDTIME': possession.get('EndTime', ''),\n",
    "                    'EVENTS': events,\n",
    "                    'FG2A': possession.get('FG2A', 0),\n",
    "                    'FG2M': possession.get('FG2M', 0),\n",
    "                    'FG3A': possession.get('FG3A', 0),\n",
    "                    'FG3M': possession.get('FG3M', 0),\n",
    "                    'GAMEDATE': possession.get('GameDate', ''),\n",
    "                    'GAMEID': game_id,\n",
    "                    'NONSHOOTINGFOULSTHATRESULTEDINFTS': possession.get('NonShootingFoulsThatResultedInFts', 0),\n",
    "                    'OFFENSIVEREBOUNDS': possession.get('OffensiveRebounds', 0),\n",
    "                    'OPPONENT': possession.get('Opponent', ''),\n",
    "                    'PERIOD': possession.get('Period', ''),\n",
    "                    'SHOOTINGFOULSDRAWN': possession.get('ShootingFoulsDrawn', 0),\n",
    "                    'STARTSCOREDIFFERENTIAL': possession.get('StartScoreDifferential', 0),\n",
    "                    'STARTTIME': possession.get('StartTime', ''),\n",
    "                    'STARTTYPE': possession.get('StartType', ''),\n",
    "                    'TURNOVERS': possession.get('Turnovers', 0),\n",
    "                    'DESCRIPTION': video_item.get('description', ''),\n",
    "                    'URL': video_item.get('url', np.nan) if video_item.get('url') else np.nan,\n",
    "                    'team': possession.get('Team', ''),\n",
    "                    'TEAM_ID': team_id\n",
    "                }\n",
    "                converted_data.append(row)\n",
    "        else:\n",
    "            # If no video data, create a single row with empty description and URL\n",
    "            row = {\n",
    "                'ENDTIME': possession.get('EndTime', ''),\n",
    "                'EVENTS': events,\n",
    "                'FG2A': possession.get('FG2A', 0),\n",
    "                'FG2M': possession.get('FG2M', 0),\n",
    "                'FG3A': possession.get('FG3A', 0),\n",
    "                'FG3M': possession.get('FG3M', 0),\n",
    "                'GAMEDATE': possession.get('GameDate', ''),\n",
    "                'GAMEID': game_id,\n",
    "                'NONSHOOTINGFOULSTHATRESULTEDINFTS': possession.get('NonShootingFoulsThatResultedInFts', 0),\n",
    "                'OFFENSIVEREBOUNDS': possession.get('OffensiveRebounds', 0),\n",
    "                'OPPONENT': possession.get('Opponent', ''),\n",
    "                'PERIOD': possession.get('Period', ''),\n",
    "                'SHOOTINGFOULSDRAWN': possession.get('ShootingFoulsDrawn', 0),\n",
    "                'STARTSCOREDIFFERENTIAL': possession.get('StartScoreDifferential', 0),\n",
    "                'STARTTIME': possession.get('StartTime', ''),\n",
    "                'STARTTYPE': possession.get('StartType', ''),\n",
    "                'TURNOVERS': possession.get('Turnovers', 0),\n",
    "                'DESCRIPTION': '',\n",
    "                'URL': np.nan,\n",
    "                'team': possession.get('Team', ''),\n",
    "                'TEAM_ID': team_id\n",
    "            }\n",
    "            converted_data.append(row)\n",
    "    \n",
    "    return converted_data\n",
    "\n",
    "def update_team_possessions(team, season, base_dir='nba_possessions_data'):\n",
    "    print(season)\n",
    "    season_str = str(season-1)+'-'+str(season)[-2:]\n",
    "    team_games = games[games['team']==team]\n",
    "    team_games = team_games[team_games['season']==season_str]\n",
    "    #team_games['GAME_ID'] = '00'+team_games['GAME_ID'].astype(str)\n",
    "    #print(team_games.head())\n",
    "    team_games = team_games[['GAME_ID','VTM','HTM']]\n",
    "    team_games.columns = ['GAMEID','VTM','HTM']\n",
    "    team_games['GAMEID'] = team_games['GAMEID'].astype(str)\n",
    "    team_games.drop_duplicates(subset='GAMEID',inplace=True)\n",
    "    #print(team_games.head())\n",
    "    \"\"\"Update possession data for a specific team from their last recorded date.\"\"\"\n",
    "    team_dict = get_team_dict()\n",
    "    team_id = team_dict[team]\n",
    "    \n",
    "    # Construct file path and create directories if needed\n",
    "    season_dir = os.path.join(base_dir, str(season))\n",
    "    os.makedirs(season_dir, exist_ok=True)\n",
    "    file_path = os.path.join(season_dir, f\"{season}_{team}_possessions.csv\")\n",
    "    \n",
    "    # Get the latest date from existing file\n",
    "    start_date = get_latest_date(file_path)\n",
    "    if start_date is None:\n",
    "        start_date = f\"{season-1}-10-22\"  # Season start date if no file exists\n",
    "    else:\n",
    "        # Add one day to the latest date to avoid duplicates\n",
    "        start_date = (pd.to_datetime(start_date) + pd.Timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Set end date to current date\n",
    "    end_date = datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "    \n",
    "    print(f\"Updating {team} data from {start_date} to {end_date}\")\n",
    "    \n",
    "    # Fetch new possessions\n",
    "    date_ranges = get_date_ranges(start_date, end_date)\n",
    "    new_possessions = []\n",
    "    \n",
    "    for start, end in date_ranges:\n",
    "        possessions = fetch_possessions(team, start, end)\n",
    "        if possessions:\n",
    "            converted_possessions = convert_new_to_old_format(possessions, team_id)\n",
    "            new_possessions.extend(converted_possessions)\n",
    "        time.sleep(2)  # API rate limiting\n",
    "    \n",
    "    if new_possessions:\n",
    "        new_df = pd.DataFrame(new_possessions)\n",
    "        new_df = new_df.merge(team_games, on='GAMEID', how='left')\n",
    "\n",
    "        \n",
    "         \n",
    "        # If file exists, append new data; otherwise create new file\n",
    "        if os.path.exists(file_path):\n",
    "            existing_df = pd.read_csv(file_path)\n",
    "            existing_df=existing_df[existing_df.GAMEDATE<=start_date]\n",
    "            #print(new_df.columns)\n",
    "            #print(existing_df.columns)\n",
    "            updated_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
    "           \n",
    "            # Remove duplicates based on all columns except index\n",
    "            for col in updated_df.columns:\n",
    "\n",
    "            \n",
    "                updated_df[col] = updated_df[col].astype(existing_df[col].dtype)\n",
    "                \n",
    " \n",
    "        \n",
    "          \n",
    "         \n",
    "                    \n",
    "            updated_df.drop_duplicates(inplace=True)\n",
    "            \n",
    "            # Sort by date and time\n",
    "            updated_df = updated_df.sort_values(['GAMEDATE', 'PERIOD', 'STARTTIME'])\n",
    "        else:\n",
    "            updated_df = new_df\n",
    "\n",
    "        \n",
    "        updated_df.to_csv(file_path, index=False)\n",
    "        print(f\"Added {len(new_possessions)} new possessions to {file_path}\")\n",
    "    else:\n",
    "        print(f\"No new possessions found for {team}\")\n",
    "\n",
    "def update_all_teams(season=2025, base_dir='nba_possessions_data'):\n",
    "    \"\"\"Update possession data for all teams.\"\"\"\n",
    "    teams = list(get_team_dict().keys())\n",
    "    \n",
    "    for team in teams:\n",
    "        print(f\"\\nProcessing {team}...\")\n",
    "        update_team_possessions(team, season, base_dir)\n",
    "        time.sleep(2)  # Delay between teams\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    season = 2025  # Current season\n",
    "    print(f\"Starting NBA possession data updater for {season} season...\")\n",
    "    update_all_teams(season)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
